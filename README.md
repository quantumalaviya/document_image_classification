# document_image_classification

Brief overview of all files:

```
.
├── README.md
├── data
│   ├── rvl_cdip_1000_samples -> the folder from the shared zip file
│   ├── train_infos.pkl -> generated by generate_infos.py
│   └── val_infos.pkl -> generated by generate_infos.py
├── dataset.py -> utils to create a hugging face dataset. If run as __main__, it will visualize the info pickles.
├── generate_infos.py -> helper script to cache OCR outputs into pickle files.
├── notebooks -> All notebooks with output cell.
│   ├── DIC_Helper_BERT.ipynb -> Method 1
│   └── DIC_Helper_LayoutLM.ipynb -> Method 2
├── run.py -> the entrypoint to the training script. Generates dataloaders and runs the training and eval script.
├── train.py -> definition of the PyTorch Lightning module that sets up the metrics and training loops
└── utils.py -> general utils for the project.
```

# DATA PREP

1. Unzip the `rvl_cdip_1000_samples 2.zip` inside data/
2. run the `generate_infos.py` folder. This will take some time but its a one-step process
3. Confirm that the data folder has the following structure:
```
   data -> Folder for the data
   ├── rvl_cdip_1000_samples
   ├── train_infos.pkl
   └── val_infos.pkl
```

# TRAIN AND EVAL
For both the tasks, `run.py` can be used. In the scope of this project, `run.py` doesn't have an argument parser. For this reason, the parameters have to be manually set inside the folder. I have tried to keep the parameters that need to be set on the top. 

A great example how each method can be run are the notebooks. Just add a way to clone the repo and link to drive containing the infos and the data zip file.

Note: There may be some TODOs and personal notes in the code comments. I have decided to leave them be for this project since I feel its mature enough for a PoC. Please feel free to discuss any design/coding choices with me.

For any doubts, please contact me at malaviyasarvagya22@gmail.com.
